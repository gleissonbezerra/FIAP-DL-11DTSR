{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNpEtqiLUVpHXLuNpXC3kgo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Dependencias"],"metadata":{"id":"NCQEpTyLTm9o"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Dropout\n","from tensorflow.keras.models import Model\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.datasets import mnist\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"OdD9CbfNXlV-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"Ejl6TbFWXnLc"}},{"cell_type":"code","source":["# Carregar o conjunto de dados MNIST\n","(X_train_full, _), (X_test, _) = mnist.load_data()\n","\n","# Normalização e Flattening\n","X_train_full = X_train_full.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","# Aplana os dados (28x28 -> 784)\n","input_dim = X_train_full.shape[1] * X_train_full.shape[2]\n","X_train_full = X_train_full.reshape((len(X_train_full), input_dim))\n","X_test = X_test.reshape((len(X_test), input_dim))\n","\n","# Separar 10% do X_train_full para ser o conjunto de validação (X_val)\n","X_train, X_val = train_test_split(\n","    X_train_full,\n","    test_size=0.1,  # 10% para validação\n","    random_state=42 # Para garantir que a separação seja a mesma toda vez\n",")"],"metadata":{"id":"LECYljrhXo6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modelo"],"metadata":{"id":"uYq0RHZlXwFq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WL4CWBc2nfwZ"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Dropout\n","from tensorflow.keras.models import Model\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.datasets import mnist\n","\n","\n","# Definir a arquitetura do autoencoder\n","input_dim = 784  # Número de features na entrada (28x28 para MNIST)\n","encoding_dim = 32  # Número de neuronios na camada de encoding\n","\n","# Encoder\n","input_layer = Input(shape=(input_dim,))\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = None ################### COMPLETE AQUI\n","\n","# Criar o modelo autoencoder\n","autoencoder = Model(inputs=input_layer, outputs=decoded)\n","\n","# Compilar o modelo\n","######## COMPLETE AQUI ################\n","\n","# Visualizar a arquitetura do autoencoder\n","autoencoder.summary()\n"]},{"cell_type":"code","source":["tf.keras.utils.plot_model(autoencoder, show_shapes=True)"],"metadata":{"id":"cXOJXsotYWRp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Treinamento"],"metadata":{"id":"3iqY86ZQX2um"}},{"cell_type":"code","source":["epochs = 15\n","# Treinar o modelo\n","log = autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=256, shuffle=True, validation_data=(X_val, X_val))\n","\n","# Avaliar o modelo nos dados de teste\n","score = autoencoder.evaluate(X_test, X_test)\n","print(\"Loss nos dados de teste:\", score)"],"metadata":{"id":"inGH1HJLX4I1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = log.history[\"loss\"]\n","val_losses = log.history[\"val_loss\"]\n","\n","data_epochs = np.arange(1, epochs+1, 1)\n","plt.plot(data_epochs, losses, color=\"yellow\", lw=5, label = 'Training Loss')\n","plt.plot(data_epochs, val_losses, color=\"red\", lw=5, label = 'Validation Loss')\n","\n","plt.xlabel('Época')\n","plt.ylabel('Perda')\n","plt.legend()"],"metadata":{"id":"fMujY74GaqXh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Teste"],"metadata":{"id":"choE5CvYX9HF"}},{"cell_type":"code","source":["# Reconstruir alguns exemplos de dados de teste e comparar com os originais\n","num_examples = 10\n","decoded_imgs = autoencoder.predict(X_test[:num_examples])\n","\n","# Plotar alguns exemplos\n","plt.figure(figsize=(20, 4))\n","for i in range(num_examples):\n","    # Imagem original\n","    ax = plt.subplot(2, num_examples, i + 1)\n","    plt.imshow(X_test[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # Imagem reconstruída pelo autoencoder\n","    ax = plt.subplot(2, num_examples, i + 1 + num_examples)\n","    plt.imshow(decoded_imgs[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","plt.show()"],"metadata":{"id":"PThFrQLQX-U_"},"execution_count":null,"outputs":[]}]}